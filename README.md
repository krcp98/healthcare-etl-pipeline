# ğŸ¥ Healthcare Data Pipeline - AWS Glue ETL

A comprehensive end-to-end healthcare data processing pipeline built with AWS Glue, demonstrating advanced ETL patterns, data quality management, and business intelligence generation.

![AWS Glue](https://img.shields.io/badge/AWS-Glue-FF9900?style=flat-square&logo=amazon-aws)
![Python](https://img.shields.io/badge/Python-3.9-3776AB?style=flat-square&logo=python)
![Apache Spark](https://img.shields.io/badge/Apache-Spark-E25A1C?style=flat-square&logo=apache-spark)
![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)

## ğŸ¯ Project Overview

This project implements a production-ready ETL pipeline for healthcare data processing, featuring:

- **5-Stage ETL Process**: Ingestion â†’ Quality â†’ Transform â†’ Metrics â†’ Export
- **Advanced Data Quality**: Multi-layered validation and cleansing
- **Business Intelligence**: Patient risk scoring, geographic analysis, performance metrics
- **Scalable Architecture**: Handles datasets from 1K to 1M+ records

## ğŸ“Š Pipeline Architecture


```tRaw Data (CSV) â†’ Data Quality â†’ Transformation â†’ Business Metrics â†’ Analytics (Parquet)
     â†“              â†“              â†“               â†“                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   S3 Raw    â”‚ â”‚  Validation  â”‚ â”‚    Joins    â”‚ â”‚     KPIs     â”‚ â”‚S3 Processed â”‚
â”‚   Storage   â”‚ â”‚   & Clean    â”‚ â”‚  & Enrich   â”‚ â”‚  & Reports   â”‚ â”‚  & Analyticsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- AWS Account with Glue access
- S3 bucket with healthcare data
- IAM role with appropriate permissions

### 1. Clone Repository
bash
git clone https://github.com/yourusername/healthcare-etl-pipeline.git
cd healthcare-etl-pipeline


### 2. Deploy to AWS Glue
bash
# Upload the script to S3
aws s3 cp src/healthcare_etl_pipeline.py s3://your-glue-scripts-bucket/

# Create Glue Job using AWS CLI
aws glue create-job --cli-input-json file://deployment/glue-job-definition.json


### 3. Configure Job Parameters
bash
--SOURCE_BUCKET: healthcare-data-lake-chauhan
--TARGET_BUCKET: healthcare-data-lake-chauhan  
--CATALOG_DATABASE: healthcare_db


### 4. Run Pipeline
bash
aws glue start-job-run --job-name healthcare-etl-pipeline


## ğŸ“‹ Data Schema

### Input Data Sources

#### Patients (patients.csv)
| Column | Type | Description |
|--------|------|-------------|
| patient_id | String | Unique patient identifier |
| first_name | String | Patient first name |
| last_name | String | Patient last name |
| age | Integer | Patient age (0-120) |
| gender | String | Patient gender |
| city | String | Patient city |
| state | String | Patient state |

#### Claims (insurance_claims.csv)
| Column | Type | Description |
|--------|------|-------------|
| claim_id | String | Unique claim identifier |
| patient_id | String | Foreign key to patients |
| claim_amount | Double | Claim amount in USD |
| claim_date | Date | Date of claim |
| claim_status | String | APPROVED/DENIED/PENDING |

#### Procedures (medical_procedures.csv)
| Column | Type | Description |
|--------|------|-------------|
| procedure_id | String | Unique procedure identifier |
| patient_id | String | Foreign key to patients |
| procedure_code | String | Medical procedure code |
| procedure_name | String | Procedure description |
| procedure_date | Date | Date of procedure |

#### Problematic Patients (problematic_patients.csv)
| Column | Type | Description |
|--------|------|-------------|
| patient_id | String | Patient ID with data quality issues |
| issue_type | String | Type of data quality problem |
| issue_description | String | Detailed description of the issue |

## ğŸ¯ Key Features

### Data Quality Management
- **Validation Rules**: Age bounds, null checks, amount limits
- **Anomaly Detection**: Uses problematic_patients.csv to identify and exclude known data quality issues
- **Data Standardization**: Name formatting, status normalization
- **Quality Scoring**: Assigns quality scores (0-100) based on validation results

### Business Intelligence
- **Patient Risk Scoring**: HIGH/MEDIUM/LOW classification
- **Geographic Analysis**: State-wise performance metrics  
- **Temporal Analytics**: Monthly trends and seasonality
- **Healthcare KPIs**: Approval rates, patient lifetime value

### Performance Optimization
- **Smart Partitioning**: Optimized for analytics queries
- **Parquet Format**: Columnar storage with compression
- **Efficient Joins**: Broadcast joins for dimension tables
- **Memory Management**: Configurable worker allocation


## ğŸ”§ Configuration

### Environment Variables
bash
export AWS_REGION=us-east-1
export SOURCE_BUCKET=your-source-bucket
export TARGET_BUCKET=your-target-bucket


### Glue Job Parameters
json
{
  "WorkerType": "G.1X",
  "NumberOfWorkers": 2,
  "Timeout": 15,
  "MaxRetries": 1,
  "GlueVersion": "4.0"
}


## ğŸ“Š Output Structure

After successful execution:

s3://your-bucket/
â”œâ”€â”€ processed-data/
â”‚   â”œâ”€â”€ patients/           # Clean patient records
â”‚   â”œâ”€â”€ claims/            # Validated claims (partitioned by status)  
â”‚   â””â”€â”€ procedures/        # Clean procedure records
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ patient-summary/   # Risk-scored patient analytics
â”‚   â”œâ”€â”€ claims-enriched/   # Enhanced claims with demographics
â”‚   â””â”€â”€ procedure-analytics/ # Procedure trend analysis
â””â”€â”€ metrics/
    â”œâ”€â”€ monthly-performance/ # Time-series KPIs
    â”œâ”€â”€ state-analysis/     # Geographic insights
    â””â”€â”€ risk-analysis/      # Risk distribution metrics


## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (git checkout -b feature/amazing-feature)
3. Commit changes (git commit -m 'Add amazing feature')
4. Push to branch (git push origin feature/amazing-feature)
5. Open Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- AWS Glue Documentation and Best Practices
- Apache Spark Performance Tuning Guidelines
- Healthcare Data Standards (HL7 FHIR)


**â­ If this project helped you learn AWS Glue, please give it a star!**
